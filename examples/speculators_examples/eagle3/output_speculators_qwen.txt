INFO 07-17 16:10:27 [__init__.py:253] Automatically detected platform cuda.
{'default': ['*'], 'help': 'Allowed origins.', 'type': <class 'str'>, 'nargs': '+'}
INFO 07-17 16:10:31 [api_server.py:1637] vLLM API server version 0.1.dev7756+g26a74b8
{'default': ['*'], 'help': 'Allowed origins.', 'type': <class 'str'>, 'nargs': '+'}
INFO 07-17 16:10:31 [cli_args.py:296] non-default args: {'model_tag': 'nm-testing/Speculator-Qwen3-8B-Eagle3-converted-0717', 'model': 'nm-testing/Speculator-Qwen3-8B-Eagle3-converted-0717', 'draft_tensor_parallel_size': 2}
INFO 07-17 16:10:31 [arg_utils.py:901] ðŸ¦… Auto-detected Eagle speculators format model
INFO 07-17 16:10:31 [arg_utils.py:902]   Target model: Qwen/Qwen3-8B
INFO 07-17 16:10:31 [arg_utils.py:903]   Draft model: nm-testing/Speculator-Qwen3-8B-Eagle3-converted-0717
INFO 07-17 16:10:31 [arg_utils.py:904]   Method: eagle3
INFO 07-17 16:10:31 [arg_utils.py:905]   Speculative tokens: 3
INFO 07-17 16:10:38 [config.py:1561] Using max model len 40960
INFO 07-17 16:10:44 [config.py:3476] Downcasting torch.float32 to torch.bfloat16.
INFO 07-17 16:10:44 [config.py:1561] Using max model len 40960
